{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we preprocess the flattened dataset used for the model prediction; we mainly perform check on the values nad improve formatting of certain columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries and dataset imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we import the required dataset and libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../datasets/flattened_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpful functions created for use later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we store the function which we are going to use several times to perform checks and corrections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use this function in order to analyze the missing values of a given column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_missing_values(df, column):\n",
    "    \"\"\"Analyze missing values in a column.\"\"\"\n",
    "    missing_count = df[column].isna().sum()\n",
    "    total_records = len(df)\n",
    "    missing_percentage = (missing_count / total_records) * 100\n",
    "    \n",
    "    print(f\"Total missing values: {missing_count}\")\n",
    "    print(f\"Missing percentage: {missing_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use this function in order to analyze numeric columns for null values and decimal places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_numeric_values(df, column):\n",
    "    \"\"\"Analyze numeric column values and decimal places.\"\"\"\n",
    "    print(f\"\\n=== {column} ===\")\n",
    "    print(f\"Data type: {df[column].dtype}\")\n",
    "    print(f\"Null values: {df[column].isnull().sum()}\")\n",
    "    \n",
    "    non_null_values = df[column].dropna()\n",
    "    decimal_places = (non_null_values % 1).apply(lambda x: len(str(x).split('.')[-1]) if x > 0 else 0)\n",
    "    print(\"\\nDecimal places distribution:\")\n",
    "    print(decimal_places.value_counts().sort_index())\n",
    "    \n",
    "    print(f\"\\nNegative values: {(non_null_values < 0).sum()}\")\n",
    "    print(f\"Zero values: {(non_null_values == 0).sum()}\")\n",
    "    print(f\"Infinite values: {np.isinf(non_null_values).sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use this function to check for inconsistencies in text columns, for example if a column has both 'Olten' and 'olten' as distinct values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_text_case_consistency(df, column, show_examples=5):\n",
    "    \"\"\"Analyze case consistency in text columns.\"\"\"\n",
    "    value_counts = df[column].value_counts()\n",
    "    value_lower = df[column].str.lower()\n",
    "    value_lower_counts = value_lower.value_counts()\n",
    "    \n",
    "    # Here we check the number distinct present values\n",
    "    print(f\"\\nValue counts - original: {len(value_counts)}\")\n",
    "    # Here we check the number distinct present values, but the values are transformed to lower case\n",
    "    print(f\"Value counts - lowercase: {len(value_lower_counts)}\")\n",
    "    \n",
    "    # If the values have different length, it means that some formatting inconsistencies are present\n",
    "    if len(value_counts) != len(value_lower_counts):\n",
    "        print(\"\\nCase inconsistencies found:\")\n",
    "        count = 0\n",
    "        for value in value_lower_counts.index:\n",
    "            if count >= show_examples:\n",
    "                break\n",
    "            mask = df[column].str.lower() == value\n",
    "            variants = df.loc[mask, column].unique()\n",
    "            if len(variants) > 1:\n",
    "                print(f\"\\nVariants for '{value}':\")\n",
    "                print(variants)\n",
    "                count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use this function specifically for postal codes, for computing constraints, and we check for insconsistencies such as 'as 543 bs' and 'AS 543 BS' as distinct values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_postal_code(df, column):\n",
    "    \"\"\"Analyze postal code formatting.\"\"\"\n",
    "    \n",
    "    # First we filter for postal codes that contain letters\n",
    "    postal_mask = df[column].str.contains('[A-Za-z]', na=False)\n",
    "    postal_with_letters = df.loc[postal_mask, column]\n",
    "    \n",
    "    # Then we get the value counts of the original values and the ones turned to lowercase\n",
    "    postal_counts = postal_with_letters.value_counts()\n",
    "    postal_lower = postal_with_letters.str.lower()\n",
    "    postal_lower_counts = postal_lower.value_counts()\n",
    "    \n",
    "    print(f\"Postal codes with letters - original count: {len(postal_counts)}\")\n",
    "    print(f\"Postal codes with letters - lowercase count: {len(postal_lower_counts)}\")\n",
    "    \n",
    "    # If there are case inconsistencies, we print them\n",
    "    if len(postal_counts) != len(postal_lower_counts):\n",
    "        print(\"\\nCase inconsistencies found:\")\n",
    "        count = 0\n",
    "        for code in postal_lower_counts.index:\n",
    "            if count >= 5:  # We print only the first 5 examples\n",
    "                break\n",
    "            variants = postal_with_letters[postal_with_letters.str.lower() == code].unique()\n",
    "            if len(variants) > 1:\n",
    "                print(f\"\\nVariants for '{code}':\")\n",
    "                print(variants)\n",
    "                count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use this function to standardize the postal code format when it's inconsistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_postal_code(x):\n",
    "    \"\"\"Standardize postal code format.\"\"\"\n",
    "    return x.upper() if isinstance(x, str) and any(c.isalpha() for c in x) else x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Price analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can view different decimal places, we should investigate that more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_columns = ['customer_price', 'expected_carrier_price', 'final_carrier_price']\n",
    "\n",
    "for col in price_columns:\n",
    "    analyze_numeric_values(df, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that rounding doesn't change anything, so these decimals are just python artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['customer_price', 'expected_carrier_price', 'final_carrier_price']:\n",
    "    orig = df[col]\n",
    "    rounded = df[col].round(2)\n",
    "    differences = (orig != rounded).sum()\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"Values changed by rounding to 2 decimals: {differences}\")\n",
    "    \n",
    "    if differences > 0:\n",
    "        print(\"Sample of changed values:\")\n",
    "        changed_mask = (orig != rounded)\n",
    "        print(\"Original vs Rounded:\")\n",
    "        comp_df = pd.DataFrame({\n",
    "            'Original': orig[changed_mask].head(),\n",
    "            'Rounded': rounded[changed_mask].head()\n",
    "        })\n",
    "        print(comp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that weight doesn't show any particular issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Weight Analysis ===\")\n",
    "print(f\"Data type: {df['weight'].dtype}\")\n",
    "print(f\"Null values: {df['weight'].isnull().sum()}\")\n",
    "\n",
    "# We check decimal places\n",
    "non_null_weights = df['weight'].dropna()\n",
    "decimal_places = (non_null_weights % 1).apply(lambda x: len(str(x).split('.')[-1]) if x > 0 else 0)\n",
    "print(\"\\nDecimal places distribution:\")\n",
    "print(decimal_places.value_counts().sort_index())\n",
    "\n",
    "# We check for data issues\n",
    "print(f\"\\nNegative values: {(non_null_weights < 0).sum()}\")\n",
    "print(f\"Zero values: {(non_null_weights == 0).sum()}\")\n",
    "print(f\"Infinite values: {np.isinf(non_null_weights).sum()}\")\n",
    "\n",
    "# We print some sample weights across different decimal places\n",
    "print(\"\\nSample weights with different decimal places:\")\n",
    "for dec in decimal_places.unique():\n",
    "   sample_mask = (decimal_places == dec)\n",
    "   if sample_mask.any():\n",
    "       print(f\"\\n{dec} decimal places:\")\n",
    "       print(non_null_weights[sample_mask].head().apply(lambda x: f\"{x:.{dec}f}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution doesn't show any signs that should be investigated more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=df[df['weight'] <= 100], x='weight', bins=50)\n",
    "plt.title('Weight Distribution (0-100 kg)')\n",
    "plt.xlabel('Weight (kg)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shipment type analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The elements of shipment type don't have any formatting problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shipment_types = df['shipment_type'].value_counts()\n",
    "print(\"\\nUnique shipment types and counts:\")\n",
    "print(shipment_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insurance type analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The elements of insurance type don't have any formattign problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_types = df['insurance_type'].value_counts()\n",
    "print(\"\\nUnique insurance types and counts:\")\n",
    "print(insurance_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Booking state analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The elements are as described in the documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booking_states = df['booking_state'].value_counts()\n",
    "print(\"\\nUnique insurance types and counts:\")\n",
    "print(booking_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Margin features analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative margin could mean that they had to do some refunds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = df['margin'].describe()\n",
    "nulls = df['margin'].isna().sum()\n",
    "\n",
    "print(\"\\nMargin Analysis:\")\n",
    "print(stats)\n",
    "print(f\"\\nNull values: {nulls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High number of null values across some features can be a common pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = df['segmentation_customer'].unique()\n",
    "nulls = df['segmentation_customer'].isna().sum()\n",
    "\n",
    "print(\"\\nSegmentation Analysis:\")\n",
    "print(stats)\n",
    "print(f\"\\nNull values: {nulls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main industry name analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A third of the industry are not present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_missing_values(df, 'main_industry_name_customer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we verify the case correctness of the industry name, by counting the values as they are, then putting them to lower case and comparing them to see if we can spot differences. \n",
    "There aren't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_text_case_consistency(df, 'main_industry_name_customer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sector name analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same number of values as for the industry name are missing, which makes sense since they are tied together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_missing_values(df, 'industry_sector_name_customer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we find no formatting issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_text_case_consistency(df, 'industry_sector_name_customer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delivery postal code analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A much lower percentage of missing values across the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_missing_values(df, 'postal_code_delivery')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are case inconsistencies among postal codes:<br>\n",
    "Postal codes with letters - original count: 11635<br>\n",
    "Postal codes with letters - lowercase count: 11607"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_postal_code(df, 'postal_code_delivery')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way we handle the inconsistencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['postal_code_delivery'] = df['postal_code_delivery'].apply(standardize_postal_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delivery city analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No delivery cicy has missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_missing_values(df, 'city_delivery')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lots of cities with inconsistencies in the case formatting:<br>\n",
    "City counts - original: 69883<br>\n",
    "City counts - lowercase: 59104"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_text_case_consistency(df, 'city_delivery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize city case format\n",
    "df['city_delivery'] = df['city_delivery'].str.lower().str.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Delivery country name analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this feature , which seems to be the country, we have a small amount of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_missing_values(df, 'name_country_delivery')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No inconsistencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_text_case_consistency(df, 'name_country_delivery')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFirst 5 name_pickup values:\")\n",
    "print(df['name_country_delivery'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iso country code delivery analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_missing_values(df, 'iso_country_code_delivery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"iso_country_code_delivery\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['iso_country_code_delivery'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_text_case_consistency(df, 'iso_country_code_delivery')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delivery continent analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_missing_values(df, 'continent_delivery')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format is respected across the unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['continent_delivery'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EU delivery analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_missing_values(df, 'EU_delivery')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's boolean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['EU_delivery'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain name analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_missing_values(df, 'domain_name_delivery')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nomain name has an established format which is respected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['domain_name_delivery'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postal code pickup analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_missing_values(df, 'postal_code_pickup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_postal_code(df, 'postal_code_pickup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['postal_code_pickup'] = df['postal_code_pickup'].apply(standardize_postal_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### City pickup analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_missing_values(df, 'city_pickup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_text_case_consistency(df, 'city_pickup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['city_pickup'] = df['city_pickup'].str.lower().str.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name Service Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_missing_values(df, 'name_service')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_text_case_consistency(df, 'name_service')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['name_service'] = df['name_service'].str.lower().str.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Service Type analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_missing_values(df, 'service_type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format is stardard across all entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['service_type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transport type analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_missing_values(df, 'transport_type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format is standard across entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['transport_type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name Carrier analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_missing_values(df, 'name_carrier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format is consistent across all the instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['name_carrier'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lms plus analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_missing_values(df, 'lms_plus')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values are consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lms_plus'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is Master analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_missing_values(df, 'is_master_customer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The boolean consistency is respected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_master_customer'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop non needed features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They won't be seen again since they were registered in the past, and this is not a time series problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_columns_to_drop = [col for col in df.columns if 'full_date' in col or 'created_date' in col]\n",
    "\n",
    "# Drop the columns\n",
    "df = df.drop(columns=date_columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we save the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = '../../../00-Project/datasets/preprocessed_flattened_dataset.csv'\n",
    "\n",
    "df.to_csv(output_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
