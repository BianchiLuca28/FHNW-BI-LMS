{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we take the star schema dataset and we flatten it into a single table, in order to use it for the model prediction task.\n",
    "\n",
    "The process will consist of merging the shipment fact table with the other dimensions, until only one table is left."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library and dataset imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we import the required libraries and the star schema dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file = '../../../00-Project/datasets/star_schema_dataset_1.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we read fact and dimension tables\n",
    "fact_shipment = pd.read_excel(excel_file, sheet_name='fact_shipment')\n",
    "dim_customer = pd.read_excel(excel_file, sheet_name='dim_customer')\n",
    "dim_delivery_address = pd.read_excel(excel_file, sheet_name='dim_delivery_address')\n",
    "dim_pickup_address = pd.read_excel(excel_file, sheet_name='dim_pickup_address')\n",
    "dim_date = pd.read_excel(excel_file, sheet_name='dim_date')\n",
    "dim_service = pd.read_excel(excel_file, sheet_name='dim_service')\n",
    "dim_carrier = pd.read_excel(excel_file, sheet_name='dim_carrier')\n",
    "dim_country = pd.read_excel(excel_file, sheet_name='dim_country')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we check if everything was imported correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial table dimensions:\n",
      "Fact Shipment: (711458, 21)\n",
      "Customer: (7935, 9)\n",
      "Delivery Address: (712272, 6)\n",
      "Pickup Address: (712272, 6)\n",
      "Date: (627, 5)\n",
      "Service: (2119, 7)\n",
      "Carrier: (237, 4)\n",
      "Country: (200, 5)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print dimensions of each table for verification\n",
    "print(\"Initial table dimensions:\")\n",
    "print(f\"Fact Shipment: {fact_shipment.shape}\")\n",
    "print(f\"Customer: {dim_customer.shape}\")\n",
    "print(f\"Delivery Address: {dim_delivery_address.shape}\")\n",
    "print(f\"Pickup Address: {dim_pickup_address.shape}\")\n",
    "print(f\"Date: {dim_date.shape}\")\n",
    "print(f\"Service: {dim_service.shape}\")\n",
    "print(f\"Carrier: {dim_carrier.shape}\")\n",
    "print(f\"Country: {dim_country.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the name column will have to be renamed each time for clarity, we do it to the original dimension of country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_country = dim_country.rename(columns={'name': 'name_country'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['country_id', 'name_country', 'iso_country_code', 'continent', 'EU'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_country.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shipment and customer merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we merge together the shipment and customer columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shipment columns: Index(['shipment_id', 'customer_price', 'expected_carrier_price',\n",
      "       'final_carrier_price', 'weight', 'shipment_type', 'insurance_type',\n",
      "       'customer_id', 'pickup_address_id', 'delivery_address_id', 'service_id',\n",
      "       'domain_name', 'booking_state', 'lms_plus', 'exworks_id', 'margin',\n",
      "       'created_date_id', 'pickup_date_id', 'real_pickup_date_id',\n",
      "       'delivery_date_id', 'real_delivery_date_id'],\n",
      "      dtype='object')\n",
      "customer columns: Index(['customer_id', 'created_date', 'domain_name', 'main_industry_name',\n",
      "       'industry_sector_name', 'segmentation', 'sequence_number',\n",
      "       'structure_number', 'is_master'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# We check the columns of both tables as reference\n",
    "print(f\"Shipment columns: {fact_shipment.columns}\")\n",
    "print(f\"customer columns: {dim_customer.columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we rename the customer columns before merging the tables. Renaming the columns on merge can lead to some misunderstandings and errors, so we prefer doing it beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after customer merge: (711458, 29)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Here we create a dictionary to rename all customer columns except customer_id\n",
    "customer_rename = {\n",
    "    col: f\"{col}_customer\" \n",
    "    for col in dim_customer.columns \n",
    "    if col != 'customer_id'\n",
    "}\n",
    "\n",
    "# Here we rename the customer columns\n",
    "dim_customer_renamed = dim_customer.copy()\n",
    "dim_customer_renamed = dim_customer_renamed.rename(columns=customer_rename)\n",
    "\n",
    "# Here we merge it with fact_shipment\n",
    "df = fact_shipment.merge(\n",
    "    dim_customer_renamed,\n",
    "    on='customer_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"Shape after customer merge: {df.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we check if everything went accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['shipment_id', 'customer_price', 'expected_carrier_price',\n",
       "       'final_carrier_price', 'weight', 'shipment_type', 'insurance_type',\n",
       "       'customer_id', 'pickup_address_id', 'delivery_address_id', 'service_id',\n",
       "       'domain_name', 'booking_state', 'lms_plus', 'exworks_id', 'margin',\n",
       "       'created_date_id', 'pickup_date_id', 'real_pickup_date_id',\n",
       "       'delivery_date_id', 'real_delivery_date_id', 'created_date_customer',\n",
       "       'domain_name_customer', 'main_industry_name_customer',\n",
       "       'industry_sector_name_customer', 'segmentation_customer',\n",
       "       'sequence_number_customer', 'structure_number_customer',\n",
       "       'is_master_customer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delivery, country and shipment mergin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we merge together the delivery and country dimensions, after which we merge the resulting table with the shipment one. We don't want to do all of them in a single chain of merges because of some naming issues that can occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country columns: Index(['country_id', 'name_country', 'iso_country_code', 'continent', 'EU'], dtype='object')\n",
      "Delivery columns: Index(['delivery_address_id', 'created_date', 'domain_name', 'country_id',\n",
      "       'postal_code', 'city'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Here we print the country and delivery columns to have as reference\n",
    "print(f\"Country columns: {dim_country.columns}\")\n",
    "print(f\"Delivery columns: {dim_delivery_address.columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the first step, we merge delivery address with country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we merge the delivery address with country\n",
    "delivery_with_country = dim_delivery_address.merge(\n",
    "    dim_country,\n",
    "    on='country_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Here we drop 'country_id' since it's not needed\n",
    "delivery_with_country = delivery_with_country.drop('country_id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['delivery_address_id', 'created_date', 'domain_name', 'postal_code',\n",
       "       'city', 'name_country', 'iso_country_code', 'continent', 'EU'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We check if everything went accordingly\n",
    "delivery_with_country.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step we rename the relevant columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we create a dictionary to rename all columns except delivery_address_id for the same reasons as in the above section\n",
    "delivery_rename = {\n",
    "    col: f\"{col}_delivery\" \n",
    "    for col in delivery_with_country.columns \n",
    "    if col != 'delivery_address_id'\n",
    "}\n",
    "\n",
    "# Here we rename the columns\n",
    "delivery_with_country = delivery_with_country.rename(columns=delivery_rename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we merge the merged table with shipment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after delivery address merges: (711458, 36)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.merge(\n",
    "    delivery_with_country,\n",
    "    on='delivery_address_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Here we drop 'delivery_address_id' since it's not needed anymore\n",
    "df = df.drop('delivery_address_id', axis=1)\n",
    "\n",
    "print(f\"Shape after delivery address merges: {df.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickup, country and df merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, as in the previous, we merge the pickup and country dimensions first, then the resulting one with the shipment table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country columns: Index(['country_id', 'name_country', 'iso_country_code', 'continent', 'EU'], dtype='object')\n",
      "Pickup columns: Index(['pickup_address_id', 'created_date', 'domain_name', 'country_id',\n",
      "       'postal_code', 'city'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Here we check the columns\n",
    "print(f\"Country columns: {dim_country.columns}\")\n",
    "print(f\"Pickup columns: {dim_pickup_address.columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the first step we merge the country with the pickup dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickup_with_country = dim_pickup_address.merge(\n",
    "    dim_country,\n",
    "    on='country_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Here we drop the country ID\n",
    "pickup_with_country = pickup_with_country.drop('country_id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pickup_address_id', 'created_date', 'domain_name', 'postal_code',\n",
       "       'city', 'name_country', 'iso_country_code', 'continent', 'EU'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickup_with_country.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a dictionary in order to change the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickup_rename = {\n",
    "    col: f\"{col}_pickup\" \n",
    "    for col in pickup_with_country.columns \n",
    "    if col != 'pickup_address_id'\n",
    "}\n",
    "\n",
    "# Here we rename the columns\n",
    "pickup_with_country = pickup_with_country.rename(columns=pickup_rename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['pickup_address_id', 'created_date_pickup', 'domain_name_pickup',\n",
      "       'postal_code_pickup', 'city_pickup', 'name_country_pickup',\n",
      "       'iso_country_code_pickup', 'continent_pickup', 'EU_pickup'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(pickup_with_country.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At last, we merge the created table with the shipment table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after delivery address merges: (711458, 43)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.merge(\n",
    "    pickup_with_country,\n",
    "    on='pickup_address_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Here we drop the pickup address as it's not needed\n",
    "df = df.drop('pickup_address_id', axis=1)\n",
    "print(f\"Shape after delivery address merges: {df.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['shipment_id', 'customer_price', 'expected_carrier_price',\n",
       "       'final_carrier_price', 'weight', 'shipment_type', 'insurance_type',\n",
       "       'customer_id', 'service_id', 'domain_name', 'booking_state', 'lms_plus',\n",
       "       'exworks_id', 'margin', 'created_date_id', 'pickup_date_id',\n",
       "       'real_pickup_date_id', 'delivery_date_id', 'real_delivery_date_id',\n",
       "       'created_date_customer', 'domain_name_customer',\n",
       "       'main_industry_name_customer', 'industry_sector_name_customer',\n",
       "       'segmentation_customer', 'sequence_number_customer',\n",
       "       'structure_number_customer', 'is_master_customer',\n",
       "       'created_date_delivery', 'domain_name_delivery', 'postal_code_delivery',\n",
       "       'city_delivery', 'name_country_delivery', 'iso_country_code_delivery',\n",
       "       'continent_delivery', 'EU_delivery', 'created_date_pickup',\n",
       "       'domain_name_pickup', 'postal_code_pickup', 'city_pickup',\n",
       "       'name_country_pickup', 'iso_country_code_pickup', 'continent_pickup',\n",
       "       'EU_pickup'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Service and carrier dimensions merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we are going to merge the service and carrier dimensions, and the resulting table in the shipment dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Service columns: Index(['service_id', 'created_date', 'name', 'service_type', 'transport_type',\n",
      "       'carrier_id', 'domain_name'],\n",
      "      dtype='object')\n",
      "carrier columns: Index(['carrier_id', 'name', 'created_date', 'domain_name'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Here we check the columns\n",
    "print(f\"Service columns: {dim_service.columns}\")\n",
    "print(f\"carrier columns: {dim_carrier.columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we rename the columns of the tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we rename the columns of carrier for clarity\n",
    "carrier_rename = {\n",
    "   col: f\"{col}_carrier\" \n",
    "   for col in dim_carrier.columns \n",
    "   if col != 'carrier_id'\n",
    "}\n",
    "\n",
    "dim_carrier = dim_carrier.rename(columns=carrier_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we do the same for the service\n",
    "service_rename = {\n",
    "   col: f\"{col}_service\" \n",
    "   for col in dim_service.columns \n",
    "   if col not in ['service_id', 'service_type', 'transport_type', 'carrier_id']\n",
    "}\n",
    "\n",
    "dim_service = dim_service.rename(columns=service_rename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can merge the carrier table into the service table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_carrier = dim_service.merge(\n",
    "   dim_carrier,\n",
    "   on='carrier_id',\n",
    "   how='left'\n",
    ")\n",
    "\n",
    "# Here we drop 'carrier_id' as it's not needed\n",
    "service_carrier = service_carrier.drop('carrier_id', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At last, we merge the resulting table into the shipment table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after service and carrier merges: (711458, 50)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.merge(\n",
    "   service_carrier,\n",
    "   on='service_id',\n",
    "   how='left'\n",
    ")\n",
    "\n",
    "# Here we drop 'service_id'\n",
    "df = df.drop('service_id', axis=1)\n",
    "\n",
    "print(f\"Shape after service and carrier merges: {df.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date dimensions merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we merge the date dimension into the different columns of shipment table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['full_date', 'year', 'month', 'quarter', 'date_id'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Here we review the columns\n",
    "print(dim_date.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after date merges: (711458, 75)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In this for loop, for each date we merge the date dimensions with it\n",
    "for date_type in ['created_date', 'pickup_date', 'delivery_date', 'real_pickup_date', 'real_delivery_date']:\n",
    "    date_id_col = f'{date_type}_id'\n",
    "    if date_id_col in df.columns:\n",
    "        df = df.merge(\n",
    "            dim_date,\n",
    "            left_on=date_id_col,\n",
    "            right_on='date_id',\n",
    "            how='left',\n",
    "            suffixes=('', f'_{date_type}')\n",
    "        )\n",
    "        # Here we rename the date columns to avoid confusion\n",
    "        df = df.rename(columns={\n",
    "            'year': f'year_{date_type}',\n",
    "            'month': f'month_{date_type}',\n",
    "            'quarter': f'quarter_{date_type}',\n",
    "            'full_date': f'full_date_{date_type}'\n",
    "        })\n",
    "        \n",
    "print(f\"Shape after date merges: {df.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['shipment_id', 'customer_price', 'expected_carrier_price',\n",
      "       'final_carrier_price', 'weight', 'shipment_type', 'insurance_type',\n",
      "       'customer_id', 'domain_name', 'booking_state', 'lms_plus', 'exworks_id',\n",
      "       'margin', 'created_date_id', 'pickup_date_id', 'real_pickup_date_id',\n",
      "       'delivery_date_id', 'real_delivery_date_id', 'created_date_customer',\n",
      "       'domain_name_customer', 'main_industry_name_customer',\n",
      "       'industry_sector_name_customer', 'segmentation_customer',\n",
      "       'sequence_number_customer', 'structure_number_customer',\n",
      "       'is_master_customer', 'created_date_delivery', 'domain_name_delivery',\n",
      "       'postal_code_delivery', 'city_delivery', 'name_country_delivery',\n",
      "       'iso_country_code_delivery', 'continent_delivery', 'EU_delivery',\n",
      "       'created_date_pickup', 'domain_name_pickup', 'postal_code_pickup',\n",
      "       'city_pickup', 'name_country_pickup', 'iso_country_code_pickup',\n",
      "       'continent_pickup', 'EU_pickup', 'created_date_service', 'name_service',\n",
      "       'service_type', 'transport_type', 'domain_name_service', 'name_carrier',\n",
      "       'created_date_carrier', 'domain_name_carrier', 'full_date_created_date',\n",
      "       'year_created_date', 'month_created_date', 'quarter_created_date',\n",
      "       'date_id', 'full_date_pickup_date', 'year_pickup_date',\n",
      "       'month_pickup_date', 'quarter_pickup_date', 'date_id_pickup_date',\n",
      "       'full_date_delivery_date', 'year_delivery_date', 'month_delivery_date',\n",
      "       'quarter_delivery_date', 'date_id_delivery_date',\n",
      "       'full_date_real_pickup_date', 'year_real_pickup_date',\n",
      "       'month_real_pickup_date', 'quarter_real_pickup_date',\n",
      "       'date_id_real_pickup_date', 'full_date_real_delivery_date',\n",
      "       'year_real_delivery_date', 'month_real_delivery_date',\n",
      "       'quarter_real_delivery_date', 'date_id_real_delivery_date'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Here we check the result\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we remove the id columns that aren't needed anymore\n",
    "columns_to_drop = [\n",
    "    'date_id',\n",
    "    'created_date_id', 'pickup_date_id', 'delivery_date_id',\n",
    "    'real_pickup_date_id', 'real_delivery_date_id',\n",
    "    'date_id_pickup_date', 'date_id_delivery_date', \n",
    "    'date_id_real_pickup_date', 'date_id_real_delivery_date'\n",
    "]\n",
    "\n",
    "df = df.drop(columns=columns_to_drop, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['shipment_id', 'customer_price', 'expected_carrier_price',\n",
      "       'final_carrier_price', 'weight', 'shipment_type', 'insurance_type',\n",
      "       'customer_id', 'domain_name', 'booking_state', 'lms_plus', 'exworks_id',\n",
      "       'margin', 'created_date_customer', 'domain_name_customer',\n",
      "       'main_industry_name_customer', 'industry_sector_name_customer',\n",
      "       'segmentation_customer', 'sequence_number_customer',\n",
      "       'structure_number_customer', 'is_master_customer',\n",
      "       'created_date_delivery', 'domain_name_delivery', 'postal_code_delivery',\n",
      "       'city_delivery', 'name_country_delivery', 'iso_country_code_delivery',\n",
      "       'continent_delivery', 'EU_delivery', 'created_date_pickup',\n",
      "       'domain_name_pickup', 'postal_code_pickup', 'city_pickup',\n",
      "       'name_country_pickup', 'iso_country_code_pickup', 'continent_pickup',\n",
      "       'EU_pickup', 'created_date_service', 'name_service', 'service_type',\n",
      "       'transport_type', 'domain_name_service', 'name_carrier',\n",
      "       'created_date_carrier', 'domain_name_carrier', 'full_date_created_date',\n",
      "       'year_created_date', 'month_created_date', 'quarter_created_date',\n",
      "       'full_date_pickup_date', 'year_pickup_date', 'month_pickup_date',\n",
      "       'quarter_pickup_date', 'full_date_delivery_date', 'year_delivery_date',\n",
      "       'month_delivery_date', 'quarter_delivery_date',\n",
      "       'full_date_real_pickup_date', 'year_real_pickup_date',\n",
      "       'month_real_pickup_date', 'quarter_real_pickup_date',\n",
      "       'full_date_real_delivery_date', 'year_real_delivery_date',\n",
      "       'month_real_delivery_date', 'quarter_real_delivery_date'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we save the processed dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = '../../../00-Project/datasets/flattened_dataset.csv'\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(output_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
